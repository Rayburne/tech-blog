<!doctype html>
<html>

<head>
  <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta name="keywords" content="" />
<meta name="description" content="I dream of painting and then I paint my dream." />
<link rel="icon" href="/icon.png" />
<link rel="stylesheet" href="/css/style.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="https://cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  <title>
Spark Streaming从读源码到放弃 | Youmi Tech Blog.
</title>
</head>

<body>

<div class="header">
    <div class="center">
        <h1><a href="/">Youmi Tech Blog.</a></h1>
        <p>I dream of painting and then I paint my dream.</p>
    </div>
    <div class="menu">
    
    <a href="/">home</a>
    
    <a href="/archives">archives</a>
    
    </div>
</div>



<div id="post" class="center">

    <h1>Spark Streaming从读源码到放弃</h1>

    <p><a href="https://github.com/TlunK">TlunK</a> Posted at Aug 02, 2016 . -

    
    <a href="/category/spark/">Spark</a> -
    
    <a href="/category/数据分析/">数据分析</a> -
    
    </p>

    <div class="content"><p>这篇文章来自于被 Spark Streaming 虐了2个月的我在拜读源码的过程中归纳出来的 Spark Streaming 中的知识, 尝试给大家解释一下 Spark Streaming 的在运行中实际发生了什么事情, 以助于 tunning 时不受制于框架的层层封装. 最佳的阅读方式是配合着 Spark Streaming 的源代码一起读, 因此我尽量加上了源代码的跳转:)</p>
<!-- more -->
<p>当然面向的是曾经用过 Spark Streaming 的读者, 如果大家没有用过, 我会尝试简单说明一下什么是Spark Streaming.</p>
<p>总的来说这次介绍 Spark Streaming 分为5个部分, 按照运行时发生的顺序, 分为如下:</p>
<ol>
<li>DAG 的生成</li>
<li>在 Driver 上启动 Streaming, 分发 Receiver</li>
<li>在 Executor 上启动 Receiver Job</li>
<li>数据流转</li>
<li>定时 Batch  Job  </li>
</ol>
<p>为了更好的说明, 我将以 github 上 spark 项目的 kafka spark streaming 的 <a href="https://github.com/apache/spark/blob/master/examples/src/main/python/streaming/kafka_wordcount.py">wordcount</a> 作为例子.</p>
<h2 id="三句话介绍什么是-spark-streaming">三句话介绍什么是 Spark Streaming</h2><p>最佳的解释当然是<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">官方文档</a>, 简而言之, 归结下面两张图.<img src="http://spark.apache.org/docs/latest/img/streaming-arch.png" alt="Spark Streaming"></p>
<p>Spark Streaming 就是一个不断从数据源中接收数据, 经过处理后输出到别的地方的一个流式处理框架. 在处理的过程中可以用到 Spark 的分布式内存计算的特性.</p>
<p><img src="http://spark.apache.org/docs/latest/img/streaming-flow.png" alt="Spark Streaming"></p>
<p>在流式处理中, Spark Streaming 将接收到的数据按照间隔时间(batch interval)分隔成一个个 batch, 以 batch 为单位处理数据, 以batch为单位输出.</p>
<h2 id="文章中提到的几个基本概念">文章中提到的几个基本概念</h2><h3 id="batch-job">Batch Job</h3><p>Spark Streaming 中, 根据时间间隔(batch interval)分成一个个 batch. 根据执行的操作, 一个 batch 对应1到多个 Batch Job. 因此在 Streaming 运行过程中会每隔一段时间向 Spark 提交1到多个 Job. Spark 以 Job 作为任务的基本单位, 进行 Scheduling 和计算.</p>
<h3 id="receiver-job">Receiver Job</h3><p>若使用到 Receiver-based 的数据输入源, 在 Streaming 运行中会生成一直不间断运行的 Receiver Job, 此 Job 在某一 Executor 上创建 Receiver 后就一直不断接收数据.</p>
<h3 id="jobstagetask">Job/Stage/Task</h3><p>一个 Job 实际上包含了一系列的操作, 如 <code>textFile.map(func1).map(func2).reduceByKey(func3).forEach(func4)</code>, 本质上是一个有向无环图(DAG), 也可以理解为一个链. Spark 会根据实际进行的操作, 将 Job 分成一或多个 Stage, 并且顺序依次执行.<br>在运行过程中, Spark 会根据 RDD 中的 partition 情况将每个 stage 分成多个 Task, 一般来说 RDD 有多少个 partition, 一个 stage 就有多少个 Task. Task 是 Executor 执行计算的任务执行单元.</p>
<hr>
<h2 id="dag的生成">DAG的生成</h2><p>图论中，如果一个有向图无法从任意顶点出发经过若干条边回到该点，则这个图是一个有向无环图（DAG图）。Spark streaming 使用 DAG 来描述程序的行为.</p>
<p><img src="https://cloud.githubusercontent.com/assets/17263732/17321822/11272a30-58cd-11e6-9a1f-bfa2a9893526.png" alt="1"></p>
<p>在有过 Spark 使用经验的同学看来, DAG 应该不陌生. 在 Spark 的 Web UI 上, 会使用 DAG 来展现每个 Job 的过程. 如我从当前线上程序中截出来的一张 DAG:</p>
<p><img src="https://cloud.githubusercontent.com/assets/17263732/17321836/230c1170-58cd-11e6-8230-c5c5238fbaf3.png" alt="dagexample"></p>
<p>回到我们的 wordcount 例子, 在<code>ssc.start()</code>之前, 将会生成如下的 DAG </p>
<pre><code class="lang-python"><span class="hljs-keyword">if</span> <span class="hljs-attr">__name__</span> == <span class="hljs-string">"__main__"</span>:
    <span class="hljs-attr">sc</span> = SparkContext(<span class="hljs-attr">appName="PythonStreamingKafkaWordCount")</span>
    <span class="hljs-attr">ssc</span> = StreamingContext(sc, <span class="hljs-number">1</span>)

    zkQuorum, <span class="hljs-attr">topic</span> = sys.argv[<span class="hljs-number">1</span>:]
    <span class="hljs-attr">kvs</span> = KafkaUtils.createStream(ssc, zkQuorum, <span class="hljs-string">"spark-streaming-consumer"</span>, {topic: <span class="hljs-number">1</span>})
    <span class="hljs-attr">lines</span> = kvs.<span class="hljs-built_in">map</span>(lambda x: x[<span class="hljs-number">1</span>])
    <span class="hljs-attr">counts</span> = lines.flatMap(lambda line: line.split(<span class="hljs-string">" "</span>)) \
        .<span class="hljs-built_in">map</span>(lambda word: (word, <span class="hljs-number">1</span>)) \
        .reduceByKey(lambda a, b: a+b)
    counts.pprint()

    ssc.start()
    ssc.awaitTermination()
</code></pre>
<p><img src="https://cloud.githubusercontent.com/assets/17263732/17321856/332fee14-58cd-11e6-917a-67c1748babe6.png" alt="exampledag2"></p>
<p>让我们来一个个地看, 按照顺序如下:</p>
<ol>
<li><p>用<code>createStream()</code>生成了 KafkaInputDStream</p>
</li>
<li><p>通过<code>map()</code>生成 MappedDStream, 取出 kafka 的消息内容</p>
</li>
<li><p>通过<code>flatMap()</code>生成 FlatMappedDStream, 取出所有的 word</p>
</li>
<li><p>通过<code>map()</code>生成 MappedDStream, 转换成 Key, Value 结构的 tuple 用于计数</p>
</li>
<li><p>通过<code>reduceByKey()</code>生成 ShuffledDStream, 根据 key 计数</p>
</li>
<li><p>通过<code>pprint()</code>生成 ForEachDStream, 执行打印操作</p>
</li>
</ol>
<p>在 StreamingContext 中, 使用 <a href="https://github.com/apache/spark/blob/d6dc12ef0146ae409834c78737c116050961f350/streaming/src/main/scala/org/apache/spark/streaming/DStreamGraph.scala">DStreamGraph</a> 来表示 DAG,  其中有两个属性, inputStreams 和 outputStreams. </p>
<pre><code class="lang-scala">  private val inputStreams = new ArrayBuffer[<span class="hljs-string">InputDStream[_</span>]]()
  private val outputStreams = new ArrayBuffer[<span class="hljs-string">DStream[_</span>]]()
</code></pre>
<p>inputStreams 用于记录数据的输入源, 在 createStream 时添加. 在此例中只有一个: KafkaInputDStream.</p>
<p>outputStreams 记录整个依赖链, 在生成 outputStream 时添加, 生成 Batch Job 时使用, 定义 Batch Job 的行为, 在此例中只有一个: ForEachDStream.</p>
<p><strong>自此, 在启动 Streaming 之前, 有了一份完整的描述整个 Streaming的DAG.</strong></p>
<h2 id="在-driver-上启动-streaming-并分发-receiver">在 Driver 上启动 Streaming 并分发 Receiver</h2><p>从调用<code>ssc.start()</code>开始, Streaming 就开始启动, 调用关系如下:</p>
<p><img src="https://cloud.githubusercontent.com/assets/17263732/17321864/419a274e-58cd-11e6-8bf3-b1b142e0e9ae.jpg" alt="2"></p>
<p>StreamingContext 中有一个成员<a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/JobScheduler.scala">JobScheduler</a>, 负责协调每个 batch job, 包括其生成和运行. scheduler.start()将创建一个<a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ReceiverTracker.scala#L105">ReceiverTracker</a>, 负责跟踪每个 Receiver 的状态.</p>
<p>按照顺序, <code>ReceiverTracker.start()</code>干了以下的一些事情:</p>
<ol>
<li>初始化 ReceiverTracker 中的 ReceiverTrackerEndpoint, 接收和处理来自 ReceiverTracker 和各个机器上的 Receiver 发来的消息.</li>
<li>从 DAG 的 inputStreams 中找到需要 Receiver 的 inputDStream, 取出它们的 Receiver</li>
<li><a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ReceiverTracker.scala#L425">runDummySparkJob</a> 这也是为什么我们启动 Streaming 后在 Web UI 上看到分成一个70个 task 的 job 会先运行的原因.</li>
<li>往 ReceiverTrackerEndpoint 发送 StartAllReceivers 的消息, 开始分发 Receiver<br>4.1 <strong><a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ReceiverSchedulingPolicy.scala#L57">ReceiverSchedulingPolicy</a>.scheduleReceivers() 决定每个 receiver 分配到哪个机器上的哪个Executor上, 默认会均匀分配到各个机器.</strong><br>4.2 <code>ReceiverTracker.startReceiver()</code> 生成 Receiver 的 RDD 和 jobFunc(jobFunc 用于在Executor 上启动此 Receiver), 并打包成一个 Job<br>4.3 <code>ssc.sparkContext.submitJob()</code> 提交 Job, 开始在 Executor 上跑</li>
</ol>
<h2 id="在-executor-上启动-receiver-job">在 Executor 上启动 Receiver Job</h2><p>Driver 上提交了 Receiver Job 之后, 分发到 Executor 上执行</p>
<ol>
<li>初始化一个<a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/receiver/ReceiverSupervisor.scala">ReceiverSupervisor</a>负责跟踪这个 Receiver</li>
<li><code>ReceiverSupervisor.start()</code> 启动 Receiver</li>
<li><strong>Receiver 根据传入的 topics 字段, 新建 N 个线程(在 topics 的字典中, 每个 topic 的数字含义为: 对此 topic 开多少个线程进行消息消费), 开始接收数据.</strong></li>
<li><code>ReceiverSupervisor.awaitTermination()</code>阻塞这个 Job, 使各个 Receiver 线程源源不断地接收数据.</li>
</ol>
<p>自此, Streaming 开始源源不断地运行, 不断地接收数据, 数据开始在系统中流转.</p>
<h2 id="数据流转">数据流转</h2><p>在 Spark Streaming 中, 数据流转过程基本上包括了 <strong>Receiver 接收数据, 数据结构化以及数据持久化, 数据定时分配给 Batch, Batch Job 定时处理数据, 垃圾数据回收</strong>. 下面列出了一张包含此过程的超级复杂的图......</p>
<p><img src="https://cloud.githubusercontent.com/assets/17263732/17321867/47b0f77a-58cd-11e6-9afe-ed06d0226a45.png" alt="3"></p>
<p>让我们分开了一个个部分地看.</p>
<p> 左边是在 Executor 上接收数据的过程由多个线程并行完成此过程, 逻辑如下
<img src="https://cloud.githubusercontent.com/assets/17263732/17322156/a412f2e2-58ce-11e6-971f-54e3c289808d.png" alt="1"></p>
<h3 id="receiver线程接收数据">Receiver线程接收数据</h3><ol>
<li>Receiver 不断地从 Kafka 接收数据(while循环中), 并且调用<a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/receiver/Receiver.scala#L118">Receiver.store()</a></li>
<li>store 方法会调用<code>ReceiverSupervisor.pushSingle()</code>, <strong>pushSingle 方法调用了<a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/receiver/RateLimiter.scala#L43">RateLimiter.waitToPush()</a> 阻塞此操作, 直到接收速率满足了 maxRate 的配置要求</strong></li>
<li>调用<a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/receiver/BlockGenerator.scala#L77">BlockGenerator</a>.addData() 将接收的消息添加到 BlockGenerator 的 buffer 中 (BlockGenerator 为 ReceiverSupervisor 的一个成员, 后续会继续说到)</li>
</ol>
<h3 id="a-hrefhttpsgithubcomapachesparkblobmasterstreamingsrcmainscalaorgapachesparkstreamingreceiverblockgeneratorscalal106blockgeneratorblockintervaltimera线程生成-block"><a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/receiver/BlockGenerator.scala#L106">BlockGenerator.blockIntervalTimer</a>线程生成 Block</h3><p> 此线程为一个定时器, 每隔一段时间(spark.streaming.blockInterval)进行一次操作, 逻辑如下:</p>
<ol>
<li>获取新的全局唯一的 blockId</li>
<li>将buffer中的数据全部取出来, 组装成 Block, put 到 BlockGenerator.blockForPushing 队列中, <strong>此队列是阻塞队列, 如果这个队列满了, 则阻塞这个线程的 put 操作.</strong></li>
</ol>
<h3 id="a-hrefhttpsgithubcomapachesparkblobmasterstreamingsrcmainscalaorgapachesparkstreamingreceiverblockgeneratorscalal110blockgeneratorblockpushingthreada线程"><a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/receiver/BlockGenerator.scala#L110">BlockGenerator.blockPushingThread</a>线程</h3><p>此线程不断地(在一个while循环中)把上一线程生成的 Block 存储并通知 driver, 逻辑如下:</p>
<ol>
<li><code>blockForPushing.poll()</code> 取出来一个 Block</li>
<li>调用<code>ReceiverSupervisor.pushAndReportBlock()</code>看方法名就知道其作用</li>
<li>生成一个<a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ReceivedBlockInfo.scala#L25">ReceivedBlockInfo</a>的实例, 封装了新接收的Block的信息. 调用并且发送AddBlock(ReceivedBlockInfo)消息到 Driver 上的 ReceiverTrackerEndpoint. 告诉 ReceiverTracker 这个 InputDStream (用 streamId 标识)有新的 Block, 这个 Block 有多少条消息, 在哪个机器上等等信息.</li>
<li>将这个 Block 存到 BlockManager 中. (根据设定的 StorageLevel, 决定存多少份/序列化方法/存在内存OR磁盘)</li>
</ol>
<h3 id="在driver上">在Driver上</h3><p>在上一条线程的第3步中, 处理发过来的<code>AddBlock(ReceivedBlockInfo)</code>的消息.</p>
<p><img src="https://cloud.githubusercontent.com/assets/17263732/17321872/50e224d6-58cd-11e6-9cd0-45a835c380e1.png" alt="driver"></p>
<p>消息被接收后, 将会调用<code>ReceiverTracker.ReceiverBlockTracker.addBlock()</code>, 此方法将 ReceivedBlockInfo 添加到 ReceivedBlockTracker.streamIdToUnallocatedBlockQueues 中. Key 为streamId, Value 为已存储但未分配的 Block 队列. <strong>定时生成 Batch Job 时, 将访问这个结构来获取每个 InputDStream 对应的未处理的 Block.</strong></p>
<h2 id="定时的batch-job">定时的Batch Job</h2><p>Spark Streaming 的定时分 Batch 处理接收的数据就是由这一部分来实现. 实际的逻辑非常简单. </p>
<p>在 Driver 的 StreamingContext 的一个成员 JobGenerator 中有这样一个定时器 </p>
<pre><code class="lang-scala">private val timer = new RecurringTimer(<span class="hljs-name">clock</span>, ssc.graph.batchDuration.milliseconds,
    longTime =&gt; eventLoop.post(<span class="hljs-name">GenerateJobs</span>(<span class="hljs-name">new</span> Time(<span class="hljs-name">longTime</span>))), <span class="hljs-string">"JobGenerator"</span>)
</code></pre>
<p>这个定时器简而言之干了一件事情, 每隔一个 batchDuration 调用 <a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/JobGenerator.scala#L242">JobGenerator.generateJobs()</a>, 此方法逻辑如下: !
<img src="https://cloud.githubusercontent.com/assets/17263732/17322115/754c166e-58ce-11e6-823c-52309f488d67.png" alt="default"></p>
<h3 id="将已经接收到的-blocks-分配给-batch">将已经接收到的 blocks 分配给 batch</h3><p>方法<code>ReceiverBlockTracker.allocateBlocksToBatch(time)</code> 将 streamIdToUnallocatedBlockQueues 中的 block 拿出来转换成 Key 为 streamId,
Value为ReceivedBlockInfo 数组的 Map, 放到 timeToAllocatedBlocks, 决定此 batch 包含哪些 block</p>
<pre><code class="lang-scala">  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> streamIdToUnallocatedBlockQueues = <span class="hljs-keyword">new</span> <span class="hljs-keyword">mutable</span>.HashMap[Int, ReceivedBlockQueue]
  <span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> timeToAllocatedBlocks = <span class="hljs-keyword">new</span> <span class="hljs-keyword">mutable</span>.HashMap[Time, AllocatedBlocks]
</code></pre>
<h3 id="生成-batch-job-并提交">生成 Batch Job 并提交</h3><p>还记得之前提到的 DAG 吗? 生成 DAG 的时候, 用 DStreamingGraph.outputStreams 记录依赖链</p>
<p><img src="https://cloud.githubusercontent.com/assets/17263732/17321885/611e14ae-58cd-11e6-9fe0-7f544d4e63df.png" alt="exampledag2"></p>
<p>生成 Job 的时候, 对每个 outputStream, 调用 outputStream.generateJobs() 方法, 生成对应的 RDD 和 jobFunc </p>
<pre><code class="lang-scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">generateJobs</span><span class="hljs-params">(time: Time)</span>:</span> Seq[Job] = {
    logDebug(<span class="hljs-string">"Generating jobs for time "</span> + time)
    val jobs = this.synchronized {
      outputStreams.flatMap { outputStream =&gt;
        val jobOption = outputStream.generateJob(time)
        jobOption.foreach(_.setCallSite(outputStream.creationSite))
        jobOption
      }
    }
    logDebug(<span class="hljs-string">"Generated "</span> + jobs.length + <span class="hljs-string">" jobs for time "</span> + time)
    jobs
  }
</code></pre>
<p>之后, 生成此 Batch 的相关信息用于监控, 再调用 JobScheduler.submitJobSet(JobSet(time, jobs, streamIdToInputInfos))</p>
<h3 id="完成后清除-block">完成后清除 Block</h3><p>完成此 Batch Job 后, 会往 JobScheduler.eventLoop 发送 clearMetaData 的事件, 让 eventLoop 线程调用 BlockManager 清除此 batch 对应的所有 Block.</p>
</div>

    

    <div class="relate">
    

    
    
    <a rel="next" href="/2016/07/163347168.html">卷积神经网络的数学推导 →</a>
    
    </div>

    <div class="comment_list hide" id="disqus_thread"></div>
    <div id="duoshuo_thread" class="comment_list hide ds-thread" data-thread-key="168828815" data-title="" data-url=""></div>

    <button class="hide" data-id="168828815" id="comment">Add Comments</button>

</div>


<div class="footer">
    <div class="center">
        &copy; 2016 Youmi Tech Blog. . <a target="_blank" href="https://github.com/AcyOrt/acyort">AcyOrt</a> . <a target="_blank" href="/rss.xml">RSS</a>
    </div>
</div>





<script src="/js/comment.js"></script>


</body>
</html>
